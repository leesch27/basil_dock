{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3768777",
   "metadata": {},
   "source": [
    "# Basil Docking V0.1 - Machine Learning Analysis\n",
    "## Purpose\n",
    "\n",
    "__Target Audience__<br>\n",
    "Undergraduate chemistry/biochemistry students and, in general, people that have little to no knowledge of protein-ligand docking and would like to understand the general process of docking a ligand to a protein receptor.\n",
    "\n",
    "__Brief Overview__<br>\n",
    "Molecular docking is a computational method used to predict where molecules are able to bind to a protein receptor and what interactions exist between the molecule (from now on, refered to as \"ligand\") and the receptor. It is a popular technique utilized in drug discovery and design, as when creating new drugs and testing existing drugs aginst new receptors, it is useful to determine the likelihood of binding prior to screening as it can be used to eliminate molecules that are unlikely to bind to the receptor. This significantly reduces the potential cost and time needed to test the efficacy of a set of possible ligands. <br>\n",
    "\n",
    "The general steps to perform molecular docking, assuming the ligand and receptor are ready to be docked, include the generation of potential ligand binding poses and the scoring of each generated pose (which predicts how strongly the ligand binds to the receptor, with a more negative score corresponding to a stronger bond). To dock a ligand to a protein, (insert text).<br>\n",
    "\n",
    "This notebook series encompasses<br>\n",
    "1. The preparation needed prior to docking (protein and ligand sanitation, ensuring files are in readable formats, and finding possible binding pockets)\n",
    "2. The process of docking ligand/s to a protein receptor using two docking engines (VINA and SMINA) and visualizing/analyzing the outputs\n",
    "3. Further data collection and manipulation\n",
    "4. __Utilizing machine learning to determine key residues (on the protein) and functional groups (on the ligand) responsible for protein-ligand binding__\n",
    "\n",
    "__Stepwise summary for this notebook (docking preparation, notebook 4 out of 4)__<br>\n",
    "- Determine the likelihood of a compound being orally bioactive using Lipinski's Rule of Five\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e1f97",
   "metadata": {},
   "source": [
    "## Table of Libraries Used\n",
    "### Operations, variable creation, and variable manipulation\n",
    "\n",
    "| Module (Submodule)| Abbreviation | Role | Citation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| numpy | np | performs mathematical operations, fixes NaN values in dataframe outputs, and gets docking box values from MDAnalysis | Harris, C.R., Millman, K.J., van der Walt, S.J. et al. Array programming with NumPy. Nature 585, 357â€“362 (2020). DOI: 10.1038/s41586-020-2649-2. (Publisher link). |\n",
    "| pandas | pd | organizes data in an easy-to-read format and allows for the exporting of data as a .csv file | The pandas development team. (2024). pandas-dev/pandas: Pandas (v2.2.3). Zenodo. https://doi.org/10.5281/zenodo.13819579 |\n",
    "| re |n/a| regular expression; finds and pulls specific strings of characters depending on need, allows for easy naming and variable creation | Van Rossum, G. (2020). The Python Library Reference, release 3.8.2. Python Software Foundation. |\n",
    "| os | n/a| allows for interaction with computer operating system, including the reading and writing of files |  Van Rossum, G. (2020). The Python Library Reference, release 3.8.2. Python Software Foundation. |\n",
    "| sys |n/a| manipulates python runtime environment |  Van Rossum, G. (2020). The Python Library Reference, release 3.8.2. Python Software Foundation.|\n",
    "\n",
    "### Protein and Ligand Preparation\n",
    "| Module (Submodule)| Abbreviation | Role | Citation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| open babel (pybel)| n/a | hygrogenates ligands and prepares ligands for docking |  O'Boyle, N.M., Banck, M., James, C.A. et al. Open Babel: An open chemical toolbox. J Cheminform 3, 33 (2011). https://doi.org/10.1186/1758-2946-3-33.|\n",
    "| rdkit (Chem)| n/a | ligand creation and sanitation |  RDKit: Open-source cheminformatics; http://www.rdkit.org |\n",
    "\n",
    "### Machine Learning Methods\n",
    "| Library/Module | Abbreviation | Role | Citation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| sklearn (RandomForestClassifier, DecisionTreeClassifier, SVC)| n/a | add descrip. |  Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011. |\n",
    "\n",
    "### Data analysis\n",
    "| Module (Submodule) | Abbreviation | Role | Citation |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| rdkit (Chem (AllChem, Crippen, Lipinski))| n/a | calculate Lipinski descriptors using RDKit mol and SMILES strings  |  RDKit: Open-source cheminformatics; http://www.rdkit.org |\n",
    "| prolif | plf | calculate, record, and view protein-ligand interactions|  chemosim-lab/ProLIF: v0.3.3 - 2021-06-11.https://doi.org/10.5281/zenodo.4386984. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156dabb6",
   "metadata": {},
   "source": [
    "For using this notebook, certain libraries are required in order for analysis to perform as planned. You can either use a conda library (provided as a yml file) or install all required libraries using pip install. Only run the cells below if you will not use a conda library to install required libraries, and only use them as needed. If you are using a conda library, start at the coding cell that imports the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f27b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, SVM, DecisionTree\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import glob\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Draw, Crippen, Lipinski\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from ipywidgets import SelectMultiple\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "IPythonConsole.ipython_useSVG=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8511b0e",
   "metadata": {},
   "source": [
    "## Lipinski's Rule of 5 and Oral Bioactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5caeff",
   "metadata": {},
   "source": [
    "(Intro)\n",
    "Lipinski's Rule of 5 (LRO5) states that drugs that meet at least three of the following criteria are likely to be orally bioactive\n",
    "1. Molecular mass less than 500 daltons\n",
    "2. Octonal-water partition coefficient that is 5 or less\n",
    "3. No more than 5 hydrogen bond donors\n",
    "4. No more than 10 hydrogen bond acceptors\n",
    "\n",
    "From this, it can bestated that in general small drugs that are more hydrophilic (low partition coefficient) that are overall stable (does not give or receive a large number of protons) are more likely to be orally bioactive than large, unstable, hydrophobic drugs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea2b1b",
   "metadata": {},
   "source": [
    "### Data Preparation and Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9eae70",
   "metadata": {},
   "source": [
    "(how is data being prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a69d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lipinski's rule of 5 and determining if a ligand/derivative is likely to be pharmacologically active using decision tree\n",
    "# (only for orally active -- look into other routes of administation too?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_csvs = []\n",
    "file_location = os.path.join('data','*.csv')\n",
    "csvs = glob.glob(file_location)\n",
    "\n",
    "for file in csvs:\n",
    "    if (\"ligand_smiles_data\" in file) or (\"deriv_smiles_data\" in file):\n",
    "        info_csvs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "select_csv = SelectMultiple(layout = {'width': 'initial'}, options = info_csvs, description = \"Select files containing ligands of interest\", style = style)\n",
    "select_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for number, csv in enumerate(select_csv.value):\n",
    "    dataframe = pd.read_csv(csv)\n",
    "    df_list.append(dataframe)\n",
    "\n",
    "lro5 = df_list[0]\n",
    "if len(df_list) > 1:\n",
    "    for value in df_list[1:]:\n",
    "        lro5 = pd.concat([lro5, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae645ac",
   "metadata": {},
   "source": [
    "(what's being done here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine and record the number of atoms and the number of heavy atoms in each ligand\n",
    "atom_type_dict = {}\n",
    "atom_abbriv = ['C','N','O','F','Al','P','S','Cl','Cr','Mn','Fe','Co','Ni','Cu',\n",
    "               'Zn','Ga','Ge','As','Br','Zr','Mo','Pd','Ag','Cd','In','Sn','Sb',\n",
    "               'I','Ir','Pt','Au','Hg','Pb','Bi']\n",
    "mol_format = []\n",
    "atom_total = []\n",
    "atom_total_heavy = []\n",
    "for index, row in lro5.iterrows():\n",
    "    try:\n",
    "        mol = Chem.MolFromMol2File(row['filename_hydrogens'],sanitize=False)\n",
    "        if mol is not None:\n",
    "            mol_H = Chem.AddHs(mol)\n",
    "            mol_format.append(mol_H)\n",
    "            mol_atoms = mol_H.GetNumAtoms()\n",
    "            atom_total.append(mol_atoms)\n",
    "            mol_atoms_heavy = mol_H.GetNumHeavyAtoms()\n",
    "            atom_total_heavy.append(mol_atoms_heavy)\n",
    "        else:\n",
    "            #currently only works for molecules containing only atoms with single letter names, need to fix\n",
    "            string = row['smiles']\n",
    "            string_alpha = re.findall(r'[a-zA-Z]', string)\n",
    "            string_H = re.findall(r'[H]', string)\n",
    "            mol_format.append(np.nan)\n",
    "            atom_total.append(len(string_alpha))\n",
    "            atom_total_heavy.append(len(string_alpha) - len(string_H))\n",
    "    except OSError:\n",
    "        mol = Chem.MolFromSmiles(row['smiles'])\n",
    "        if mol is not None:\n",
    "            mol_H = Chem.AddHs(mol)\n",
    "            mol_format.append(mol_H)\n",
    "            mol_atoms = mol_H.GetNumAtoms()\n",
    "            atom_total.append(mol_atoms)\n",
    "            mol_atoms_heavy = mol_H.GetNumHeavyAtoms()\n",
    "            atom_total_heavy.append(mol_atoms_heavy)\n",
    "        else:\n",
    "            #currently only works for molecules containing only atoms with single letter names, need to fix\n",
    "            string = row['smiles']\n",
    "            string_alpha = re.findall(r'[a-zA-Z]', string)\n",
    "            string_H = re.findall(r'[H]', string)\n",
    "            mol_format.append(np.nan)\n",
    "            atom_total.append(len(string_alpha))\n",
    "            atom_total_heavy.append(len(string_alpha) - len(string_H))\n",
    "lro5['mol'] = mol_format\n",
    "lro5['num_of_atoms'] = atom_total\n",
    "lro5['num_of_heavy_atoms'] = atom_total_heavy\n",
    "lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85b947",
   "metadata": {},
   "source": [
    "(whats happening here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90718b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of different heavy atoms\n",
    "# LEE - TEST WITH LIG CONT. Co2+ or Co3+\n",
    "num_of_atoms_dict = {}\n",
    "def number_of_atoms(atom_list, df):\n",
    "    for i in atom_list:\n",
    "        substruct_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            smile_string = row['smiles']\n",
    "            if len(i) == 1:\n",
    "                string_finder_lower = re.findall(r'{}(?![aelu+][+\\d])(?!([aeolu]+[+\\d]))'.format(i.lower()), smile_string)\n",
    "                string_finder_upper = re.findall(r'{}(?![aelu+][+\\d])(?!([aeolu]+[+\\d]))'.format(i), smile_string)\n",
    "                substruct_list.append(len(string_finder_lower) + len(string_finder_upper))\n",
    "            else:\n",
    "                string_finder_brackets = re.findall(r'[\\[]{}[\\]]'.format(i), smile_string)\n",
    "                string_finder_charged = re.findall(r'[\\[]{}[+][+\\d]'.format(i), smile_string)\n",
    "                substruct_list.append(len(string_finder_brackets) + len(string_finder_charged))\n",
    "        df['num_of_{}_atoms'.format(i)] = substruct_list\n",
    "\n",
    "number_of_atoms(atom_abbriv, lro5)\n",
    "lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1cb0b",
   "metadata": {},
   "source": [
    "(what's being done here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7465125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weight of ligands\n",
    "atom_weights = {\n",
    "    'C':12.0096,\n",
    "    'N': 14.006,\n",
    "    'O': 15.999,\n",
    "    'F': 18.998,\n",
    "    'Al': 26.981,\n",
    "    'P': 30.974,\n",
    "    'S': 32.059,\n",
    "    'Cl': 35.45,\n",
    "    'Cr': 51.9961,\n",
    "    'Mn': 54.938,\n",
    "    'Fe': 55.845,\n",
    "    'Co': 58.933,\n",
    "    'Ni': 58.693,\n",
    "    'Cu': 63.546,\n",
    "    'Zn': 65.38,\n",
    "    'Ga': 69.723,\n",
    "    'Ge': 72.630,\n",
    "    'As': 74.921,\n",
    "    'Br': 79.901,\n",
    "    'Zr': 91.224,\n",
    "    'Mo': 95.95,\n",
    "    'Pd': 106.42,\n",
    "    'Ag': 107.8682,\n",
    "    'Cd': 112.414,\n",
    "    'In': 114.818,\n",
    "    'Sn': 118.71,\n",
    "    'Sb': 121.760,\n",
    "    'I': 126.904,\n",
    "    'Ir': 192.217,\n",
    "    'Pt': 195.08,\n",
    "    'Au': 196.966570,\n",
    "    'Hg': 200.592,\n",
    "    'Pb': 207.2,\n",
    "    'Bi': 208.980\n",
    "}\n",
    "ligand_weights = []\n",
    "for index, row in lro5.iterrows():\n",
    "    ligand_atom_nums = sum(row[5:])\n",
    "    weight_da = 0\n",
    "    if row['num_of_heavy_atoms'] == ligand_atom_nums:\n",
    "        for num, column in enumerate(row[5:]):\n",
    "            column_title = list(lro5)[num + 5]\n",
    "            atom_name = re.split(\"_\", column_title)\n",
    "            atom_type_weight = atom_weights[atom_name[2]]\n",
    "            weight_da = weight_da + (atom_type_weight *  column)\n",
    "    weight_da = weight_da + ((row.iloc[3] - row.iloc[4]) * 1.007)\n",
    "    ligand_weights.append(weight_da)\n",
    "lro5.insert(2, \"molecular_weight\", ligand_weights)\n",
    "lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa93387",
   "metadata": {},
   "source": [
    "(what's being added to the dataframe in the cell below?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate logP (partition coefficient), hydrogen bond donors, hydrogen bond acceptors,\n",
    "# molar refractivity (Ghose filter), number of rotatable bonds (veber's rule) and polar surface\n",
    "# area (veber's rule) of ligands\n",
    "log_P = []\n",
    "H_donors = []\n",
    "H_acceptors = []\n",
    "mol_mr = []\n",
    "mol_rotatable = []\n",
    "tpsas = []\n",
    "for index, row in lro5.iterrows():\n",
    "    mol = row.iloc[3]\n",
    "    if type(mol) != float:\n",
    "        log = Crippen.MolLogP(mol)\n",
    "        log_P.append(log)\n",
    "        donor = Lipinski.NumHDonors(mol)\n",
    "        H_donors.append(donor)\n",
    "        acceptor = Lipinski.NumHAcceptors(mol)\n",
    "        H_acceptors.append(acceptor)\n",
    "        mr = Crippen.MolMR(mol)\n",
    "        mol_mr.append(mr)\n",
    "        rotatable = Lipinski.NumRotatableBonds(mol)\n",
    "        mol_rotatable.append(rotatable)\n",
    "        psa = Descriptors.TPSA(mol)\n",
    "        tpsas.append(psa)\n",
    "    else:\n",
    "        pass\n",
    "lro5.insert(3, \"log_P\", log_P)\n",
    "lro5.insert(4, \"H_donors\", H_donors)\n",
    "lro5.insert(5, \"H_acceptors\", H_acceptors)\n",
    "lro5.insert(6, \"mol_refractivity\", mol_mr)\n",
    "lro5.insert(7, \"rotatable_bonds\", mol_rotatable)\n",
    "lro5.insert(8, \"polar_surface_area\", tpsas)\n",
    "lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9b699f",
   "metadata": {},
   "source": [
    "### Using Machine Learning to determine Orally Bioactive Drugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac9b0ca",
   "metadata": {},
   "source": [
    "(What's happening here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioactive_df = pd.read_csv(\"data/oral_bioactive_test_train.csv\")\n",
    "try:\n",
    "    bioactive_df = pd.concat([bioactive_df, lro5])\n",
    "except:\n",
    "    bioactive_df = pd.read_csv(\"data/oral_bioactive_test_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adb039",
   "metadata": {},
   "source": [
    "(Whats happening?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lro5 = bioactive_df.drop(columns = [\"filename_hydrogens\", \"smiles\", \"mol_refractivity\", \"rotatable_bonds\", \"polar_surface_area\", \"orally_bioactive\", \"mol\"])\n",
    "target = bioactive_df[\"orally_bioactive\"]\n",
    "X_train_lro5, X_test_lro5, y_train_lro5, y_test_lro5 = train_test_split(features_lro5, target, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_lro5 = RandomForestClassifier()\n",
    "rf_lro5.fit(X_train, y_train)\n",
    "scores_lro5 = cross_validate(rf_lro5, X_train_lro5, y_train_lro5, return_train_score=True)\n",
    "scores_df_lro5 = pd.DataFrame(scores_lro5)\n",
    "scores_df_lro5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f800a4",
   "metadata": {},
   "source": [
    "(talk about hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f7341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    \"max_depth\": [1, 5, 10, 15, 20],\n",
    "    \"max_features\": [1, 5, 10, 15, 20],\n",
    "    \"min_samples_split\": [10, 20, 30, 40, 50],\n",
    "    \"min_samples_leaf\": [5, 10, 15, 20]\n",
    "}\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), param_distributions=rf_param_grid, n_jobs=-1, n_iter=10, cv=5, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af06dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search.fit(X_train_lro5, y_train_lro5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d12b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random_search.cv_results_)[\n",
    "    [\"mean_test_score\",\"param_max_depth\",\"param_max_features\", \"param_min_samples_split\", \"param_min_samples_leaf\", \"mean_fit_time\",\"rank_test_score\",]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee85ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal_lro5 = RandomForestClassifier(max_depth = 15, max_features=5, min_samples_split = 30, min_samples_leaf = 10)\n",
    "rf_optimal_lro5.fit(X_train_lro5, y_train_lro5)\n",
    "rf_optimal_lro5.score(X_test_lro5, y_test_lro5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a93b8b7",
   "metadata": {},
   "source": [
    "(ooooo feature importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac85745",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_lro5.columns)\n",
    "data = {\n",
    "    \"Importance\": rf_optimal_lro5.feature_importances_,\n",
    "}\n",
    "imps = pd.DataFrame(data=data, index=feature_names,).sort_values(by=\"Importance\", ascending=False)[:10]\n",
    "imps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18726a",
   "metadata": {},
   "source": [
    "## Lipinski's Rule of 5 Variants and Oral Bioactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7796b",
   "metadata": {},
   "source": [
    "(Why are there variants?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4422bc0",
   "metadata": {},
   "source": [
    "### The Ghose Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d925c",
   "metadata": {},
   "source": [
    "The Ghose filter further refines the rules set up by LRO5 by adding the following criteria:\n",
    "1. Octonal-water partition coefficient is between -0.4 and +5.6\n",
    "2. Molar refractivity is between 40 and 130\n",
    "3. Molecular weight is between 180 and 480 daltons\n",
    "4. Number of atoms is between 20 and 70 (including hydrogen bond donors and acceptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec306e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ghose = bioactive_df.drop(columns = [\"filename_hydrogens\", \"smiles\", \"rotatable_bonds\", \"polar_surface_area\", \"orally_bioactive\", \"mol\"])\n",
    "target = bioactive_df[\"orally_bioactive\"]\n",
    "X_train_ghose, X_test_ghose, y_train_ghose, y_test_ghose = train_test_split(features_ghose, target, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), param_distributions=rf_param_grid, n_jobs=-1, n_iter=10, cv=5, random_state=123\n",
    ")\n",
    "rf_random_search.fit(X_train_ghose, y_train_ghose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random_search.cv_results_)[\n",
    "    [\"mean_test_score\",\"param_max_depth\",\"param_max_features\", \"param_min_samples_split\", \"param_min_samples_leaf\", \"mean_fit_time\",\"rank_test_score\",]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd38481",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal_ghose = RandomForestClassifier(max_depth = 15, max_features=5, min_samples_split = 30, min_samples_leaf = 10)\n",
    "rf_optimal_ghose.fit(X_train_ghose, y_train_ghose)\n",
    "rf_optimal_ghose.predict(X_test_ghose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426592b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_ghose.columns)\n",
    "data = {\n",
    "    \"Importance\": rf_optimal_ghose.feature_importances_,\n",
    "}\n",
    "imps = pd.DataFrame(data=data, index=feature_names,).sort_values(by=\"Importance\", ascending=False)[:10]\n",
    "imps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9e232",
   "metadata": {},
   "source": [
    "### Veber's Rule and Oral Bioactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0a19e",
   "metadata": {},
   "source": [
    "Veber's rule completely changes the prediction methods to determine orally bioactive drugs, only checking for two criteria:\n",
    "1. The molecule has 10 or fewer rotatable bonds\n",
    "2. The molecule has a polar surface area equal to 140 square angstroms or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_veber = bioactive_df.drop(columns = [\"filename_hydrogens\", \"smiles\", \"orally_bioactive\", \"mol\"])\n",
    "target = bioactive_df[\"orally_bioactive\"]\n",
    "X_train_veber, X_test_veber, y_train_veber, y_test_veber = train_test_split(features_veber, target, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e47466",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(), param_distributions=rf_param_grid, n_jobs=-1, n_iter=10, cv=5, random_state=123\n",
    ")\n",
    "rf_random_search.fit(X_train_veber, y_train_veber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random_search.cv_results_)[\n",
    "    [\"mean_test_score\",\"param_max_depth\",\"param_max_features\", \"param_min_samples_split\", \"param_min_samples_leaf\", \"mean_fit_time\",\"rank_test_score\",]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ea32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal_veber = RandomForestClassifier(max_depth = 15, max_features=5, min_samples_split = 30, min_samples_leaf = 10)\n",
    "rf_optimal_veber.fit(X_train_veber, y_train_veber)\n",
    "rf_optimal_veber.predict(X_test_veber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27455f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_veber.columns)\n",
    "data = {\n",
    "    \"Importance\": rf_optimal_veber.feature_importances_,\n",
    "}\n",
    "imps = pd.DataFrame(data=data, index=feature_names,).sort_values(by=\"Importance\", ascending=False)[:10]\n",
    "imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine important residues/residue types (receptor), fxnal groups (ligand), and important interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2_present = False\n",
    "N3_present = False\n",
    "try:\n",
    "    #data from notebook 2: docking and preliminary analysis\n",
    "    notebook_2_data = pd.read_csv('data/docking_information.csv')\n",
    "    notebook_2_features = notebook_2_data.drop(columns = [\"Score\"])\n",
    "    notebook_2_target = notebook_2_data[\"Score\"]\n",
    "    #data from notebook 3: data collection and manipulation\n",
    "    notebook_3_data = pd.read_csv('data/deriv_information.csv')\n",
    "    notebook_3_features = notebook_3_data.drop(columns = [\"Score\"])\n",
    "    notebook_3_target = notebook_3_data[\"Score\"]\n",
    "    N2_present = True\n",
    "    N3_present = True\n",
    "    print(\"Notebook 2 data and notebook 3 data is available for analysis\")\n",
    "except:\n",
    "    try:\n",
    "        notebook_2_data = pd.read_csv('data/docking_information.csv')\n",
    "        notebook_2_features = notebook_2_data.drop(columns = [\"Score\"])\n",
    "        notebook_2_target = notebook_2_data[\"Score\"]\n",
    "        N2_present = True\n",
    "        print(\"Notebook 2 data is available for analysis\")\n",
    "    except:\n",
    "        notebook_3_data = pd.read_csv('data/deriv_information.csv')\n",
    "        notebook_3_features = notebook_3_data.drop(columns = [\"Score\"])\n",
    "        notebook_3_target = notebook_3_data[\"Score\"]\n",
    "        N3_present = True\n",
    "        print(\"Notebook 3 data is available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if N2_present:\n",
    "    X_train_N2, X_test_N2, y_train_N2, y_test_N2 = train_test_split(notebook_2_features, notebook_2_target, random_state = 27)\n",
    "if N3_present:\n",
    "    X_train_N3, X_test_N3, y_train_N3, y_test_N3 = train_test_split(notebook_3_features, notebook_3_target, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de51548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(), param_distributions=rf_param_grid, n_jobs=-1, n_iter=10, cv=5, random_state=123\n",
    ")\n",
    "rf_random_search.fit(X_train_N2, y_train_N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random_search.cv_results_)[\n",
    "    [\"mean_test_score\",\"param_max_depth\",\"param_max_features\", \"param_min_samples_split\", \"param_min_samples_leaf\", \"mean_fit_time\",\"rank_test_score\",]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d61cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal_N2 = RandomForestRegressor(max_depth = 15, max_features=5, min_samples_split = 30, min_samples_leaf = 10)\n",
    "rf_optimal_N2.fit(X_train_N2, y_train_N2)\n",
    "rf_optimal_N2.predict(X_test_N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99780931",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_N2.columns)\n",
    "data = {\n",
    "    \"Importance\": rf_optimal_N2.feature_importances_,\n",
    "}\n",
    "imps = pd.DataFrame(data=data, index=feature_names,).sort_values(by=\"Importance\", ascending=False)[:10]\n",
    "imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c118f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(), param_distributions=rf_param_grid, n_jobs=-1, n_iter=10, cv=5, random_state=123\n",
    ")\n",
    "rf_random_search.fit(X_train_N3, y_train_N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b161885",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_random_search.cv_results_)[\n",
    "    [\"mean_test_score\",\"param_max_depth\",\"param_max_features\", \"param_min_samples_split\", \"param_min_samples_leaf\", \"mean_fit_time\",\"rank_test_score\",]\n",
    "].set_index(\"rank_test_score\").sort_index().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10b42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal_N3 = RandomForestRegressor(max_depth = 15, max_features=5, min_samples_split = 30, min_samples_leaf = 10)\n",
    "rf_optimal_N3.fit(X_train_N3, y_train_N3)\n",
    "rf_optimal_N3.predict(X_test_N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef748f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(X_train_N3.columns)\n",
    "data = {\n",
    "    \"Importance\": rf_optimal_N3.feature_importances_,\n",
    "}\n",
    "imps = pd.DataFrame(data=data, index=feature_names,).sort_values(by=\"Importance\", ascending=False)[:10]\n",
    "imps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
